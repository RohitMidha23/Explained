{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Linear Regression - Complex.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmAfAVhFhLO1",
        "colab_type": "text"
      },
      "source": [
        "# The Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsU-gDo8goJA",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial we use a special package called hiddenlayer.\n",
        "\n",
        "It's very easy to install and serves as a way to visualize Pytorch graphs.\n",
        "\n",
        "To install, use `pip install hiddenlayer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8udM2x5pgIdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d0c8295-71bf-4e79-bfd2-b58536d5b636"
      },
      "source": [
        "! pip install hiddenlayer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hiddenlayer in /usr/local/lib/python3.6/dist-packages (0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUfHVTKHfKh5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8dae50de-c997-4625-ac4c-df2bf41e2660"
      },
      "source": [
        "# Necessary imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import graphviz\n",
        "import hiddenlayer as hl\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im5w8fhlgnS9",
        "colab_type": "text"
      },
      "source": [
        "The dataset we use is the Bike Sharing Demand Dataset which you can get by registering [here](https://www.kaggle.com/c/bike-sharing-demand/data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LRRm7gohJrM",
        "colab_type": "text"
      },
      "source": [
        "Now that we have the necessary things ready, let's get into the thick of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oVAr--ehSY4",
        "colab_type": "text"
      },
      "source": [
        "# The Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh4GjjINfnKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"train.csv\", index_col = 0, nrows=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0H_gPxnnDGo",
        "colab_type": "text"
      },
      "source": [
        "For the sake of the tutorial we only use 1000 rows, but you can use the entire dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3B-S6wPhVm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90943511-f0d3-43be-9b6f-d21f92175aeb"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL4C9nlrh16W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8cc51946-b34c-4fee-8a5d-bd69b28295df"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2011-01-01 00:00:00</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-01 01:00:00</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-01 02:00:00</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-01 03:00:00</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-01 04:00:00</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     season  holiday  workingday  ...  casual  registered  count\n",
              "datetime                                          ...                           \n",
              "2011-01-01 00:00:00       1        0           0  ...       3          13     16\n",
              "2011-01-01 01:00:00       1        0           0  ...       8          32     40\n",
              "2011-01-01 02:00:00       1        0           0  ...       5          27     32\n",
              "2011-01-01 03:00:00       1        0           0  ...       3          10     13\n",
              "2011-01-01 04:00:00       1        0           0  ...       0           1      1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoxrnHNXhj0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "d3c4cb6c-74b2-441f-c2dd-7487874c3177"
      },
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.barplot('holiday', 'count', hue='season', data=data)\n",
        "plt.title(\"Number of bikes rented!\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws7tOhtbirH7",
        "colab_type": "text"
      },
      "source": [
        "I'm going to leave further exploration up to you, the reader. \n",
        "\n",
        "If you have any doubts on how to use `matplotlib` you can refer to [my  other tutorial on Matplotlib](https://rohitmidha23.github.io/Matplotlib-Explained/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR39eSxBjDem",
        "colab_type": "text"
      },
      "source": [
        "# The Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW6cXsCIjTb8",
        "colab_type": "text"
      },
      "source": [
        "We will use only a few columns for the final features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nD_hUr5h0Pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['season', 'holiday', 'workingday', 'weather', 'temp',\n",
        "           'atemp', 'humidity', 'windspeed', 'casual', 'registered']\n",
        "\n",
        "features = data[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyasikU1jQme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = data[\"count\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-1ozYzijpVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13f2b550-13b3-4fed-9f62-c4dfba504ddb"
      },
      "source": [
        "# Let's split the data into train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,\n",
        "                                                    target,\n",
        "                                                    test_size=0.2)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(800, 10) (800,)\n",
            "(200, 10) (200,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu8nHBRTjzUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the data to torch tensors\n",
        "train_x = torch.tensor(X_train.values, dtype=torch.float)\n",
        "test_x = torch.tensor(X_test.values, dtype=torch.float)\n",
        "\n",
        "train_y = torch.tensor(y_train.values, dtype=torch.float)\n",
        "test_y = torch.tensor(y_test.values, dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRb-3qiCkLP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data into pytorch required format\n",
        "import torch.utils.data as data_utils\n",
        "train_data = data_utils.TensorDataset(train_x, train_y)\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=100, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3deE2xOk2gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To be able to use the data in batches, we use the `iter` function \n",
        "features_batch, target_batch = iter(train_loader).next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz_EpwicnZ3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2144fea4-2e1f-44a0-8ab2-3944c68e4dc8"
      },
      "source": [
        "print(features_batch.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8NyJfh7oxAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1906fe1-493d-4168-ffdb-2ce1e3af1f7f"
      },
      "source": [
        "print(target_batch.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5qLxcfgncER",
        "colab_type": "text"
      },
      "source": [
        "`features_batch` here represents one batch of the entire training data.\n",
        "\n",
        "We had 1000 rows and we used `batch_size=100` hence `features_batch` has 100 rows as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxTUrJ3lmqTm",
        "colab_type": "text"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iPcgMnplE8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define some parameters\n",
        "input_shape = train_x.shape[1]\n",
        "output_shape = 1\n",
        "hidden_layers = 10\n",
        "loss_func = torch.nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RspHJ08CleqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "model = torch.nn.Sequential(torch.nn.Linear(input_shape, hidden_layers),\n",
        "                         torch.nn.Linear(hidden_layers, output_shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jq1b-JCppOo",
        "colab_type": "text"
      },
      "source": [
        "Notice how the output of first layer has the same shape as input to the second layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvwHn_83lqXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "d64eca75-94b4-4c60-c0cd-1bb37c1322a2"
      },
      "source": [
        "# Visualize the model using `hiddenlayer` package\n",
        "hl.build_graph(model, torch.zeros([10, input_shape]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<hiddenlayer.graph.Graph at 0x7fadc52a7a58>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"198pt\" height=\"116pt\"\n viewBox=\"0.00 0.00 198.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 80)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-72,36 -72,-80 126,-80 126,36 -72,36\"/>\n<!-- 12497921269257812521 -->\n<g id=\"node1\" class=\"node\">\n<title>12497921269257812521</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-44 0,-44 0,0 54,0 54,-44\"/>\n<text text-anchor=\"start\" x=\"14\" y=\"-28\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n<text text-anchor=\"start\" x=\"34\" y=\"-7\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x2</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFpqA-a9l7d6",
        "colab_type": "text"
      },
      "source": [
        "It shows us that we have 2 Linear layers, just as we defined it!\n",
        "\n",
        "\n",
        "We now need to define an optimizer. \n",
        "\n",
        "An optimizer is an object that is able to update all the models paramters using in built torch functionality. This is much easier to use than to manually update the weights ourselves!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxPxr3Vrl5zm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdLHwaT2mr1O",
        "colab_type": "text"
      },
      "source": [
        "# The Training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai4QnxAZmf9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "911901e0-4280-4fbd-a0fd-07158b105f8f"
      },
      "source": [
        "total_steps = len(train_loader)\n",
        "num_epochs = 10000\n",
        "for epoch in range(num_epochs + 1):\n",
        "  for i, (inputs, target) in enumerate(train_loader): \n",
        "    # here features and target are one batch of the training data like explained above\n",
        "\n",
        "    # perform a forward pass\n",
        "    output = model(inputs)\n",
        "    # calculate the loss\n",
        "    loss = loss_func(output, target)\n",
        "\n",
        "    # make the gradients zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backpropogate\n",
        "    loss.backward()\n",
        "\n",
        "    # update the parameters. Notice how simple it is here\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 2000 == 0:\n",
        "      print(\"Epoch [{}/{}]: Step[{}/{}], Loss:{:.4f}\"\n",
        "              .format(epoch+1, num_epochs, i+1, total_steps, loss.item()))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10000]: Step[1/8], Loss:3282.0115\n",
            "Epoch [1/10000]: Step[2/8], Loss:3065.8315\n",
            "Epoch [1/10000]: Step[3/8], Loss:3550.5315\n",
            "Epoch [1/10000]: Step[4/8], Loss:3244.2869\n",
            "Epoch [1/10000]: Step[5/8], Loss:3749.1912\n",
            "Epoch [1/10000]: Step[6/8], Loss:3523.2688\n",
            "Epoch [1/10000]: Step[7/8], Loss:3556.7913\n",
            "Epoch [1/10000]: Step[8/8], Loss:3748.4592\n",
            "Epoch [2001/10000]: Step[1/8], Loss:3296.5720\n",
            "Epoch [2001/10000]: Step[2/8], Loss:3847.5923\n",
            "Epoch [2001/10000]: Step[3/8], Loss:2398.2815\n",
            "Epoch [2001/10000]: Step[4/8], Loss:3496.5776\n",
            "Epoch [2001/10000]: Step[5/8], Loss:4121.9551\n",
            "Epoch [2001/10000]: Step[6/8], Loss:2642.0327\n",
            "Epoch [2001/10000]: Step[7/8], Loss:3260.0356\n",
            "Epoch [2001/10000]: Step[8/8], Loss:3707.0972\n",
            "Epoch [4001/10000]: Step[1/8], Loss:3247.1775\n",
            "Epoch [4001/10000]: Step[2/8], Loss:3465.2959\n",
            "Epoch [4001/10000]: Step[3/8], Loss:2906.5935\n",
            "Epoch [4001/10000]: Step[4/8], Loss:3023.2544\n",
            "Epoch [4001/10000]: Step[5/8], Loss:2567.9910\n",
            "Epoch [4001/10000]: Step[6/8], Loss:3718.7825\n",
            "Epoch [4001/10000]: Step[7/8], Loss:3736.2141\n",
            "Epoch [4001/10000]: Step[8/8], Loss:4090.5081\n",
            "Epoch [6001/10000]: Step[1/8], Loss:3859.3101\n",
            "Epoch [6001/10000]: Step[2/8], Loss:3873.6516\n",
            "Epoch [6001/10000]: Step[3/8], Loss:3024.7444\n",
            "Epoch [6001/10000]: Step[4/8], Loss:2891.5762\n",
            "Epoch [6001/10000]: Step[5/8], Loss:2543.3599\n",
            "Epoch [6001/10000]: Step[6/8], Loss:3624.6553\n",
            "Epoch [6001/10000]: Step[7/8], Loss:4131.1685\n",
            "Epoch [6001/10000]: Step[8/8], Loss:2799.2190\n",
            "Epoch [8001/10000]: Step[1/8], Loss:3553.4956\n",
            "Epoch [8001/10000]: Step[2/8], Loss:3211.1287\n",
            "Epoch [8001/10000]: Step[3/8], Loss:2801.9431\n",
            "Epoch [8001/10000]: Step[4/8], Loss:4875.0898\n",
            "Epoch [8001/10000]: Step[5/8], Loss:2408.1021\n",
            "Epoch [8001/10000]: Step[6/8], Loss:2821.6018\n",
            "Epoch [8001/10000]: Step[7/8], Loss:3497.8740\n",
            "Epoch [8001/10000]: Step[8/8], Loss:3590.0503\n",
            "Epoch [10001/10000]: Step[1/8], Loss:2453.6292\n",
            "Epoch [10001/10000]: Step[2/8], Loss:4270.7446\n",
            "Epoch [10001/10000]: Step[3/8], Loss:2779.2837\n",
            "Epoch [10001/10000]: Step[4/8], Loss:3068.2778\n",
            "Epoch [10001/10000]: Step[5/8], Loss:3535.3823\n",
            "Epoch [10001/10000]: Step[6/8], Loss:3683.9949\n",
            "Epoch [10001/10000]: Step[7/8], Loss:4048.2344\n",
            "Epoch [10001/10000]: Step[8/8], Loss:2899.5249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-RTjpdGqCZA",
        "colab_type": "text"
      },
      "source": [
        "# The Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyK36kHiqKeG",
        "colab_type": "text"
      },
      "source": [
        "To evaluate the model we switch to evaluation mode. \n",
        "\n",
        "This is because the `Dropout` and `BatchNormalization` layers have different models for evaluation and training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEBKauKMntqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "# Predict on the test set\n",
        "with torch.no_grad():\n",
        "  # Anything inside `torch.no_grad()`\n",
        "  # puts the `requires_grad` property to False.\n",
        "  y_pred = model(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSJNy50JqcWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0099c1e9-09c0-417b-a7a6-6b4fee66684a"
      },
      "source": [
        "# convert the tensor to a numpy array\n",
        "y_pred = y_pred.detach().numpy()\n",
        "print(y_pred.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqvfL_GKrDQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7624fd02-55e8-4239-cefa-074ddd9d7c68"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhBgB_e_rOj0",
        "colab_type": "text"
      },
      "source": [
        "Both are the same shape so we can continue to evaluate the model.\n",
        "\n",
        "To evaluate the model we use the r2 (r-square) score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNTxr_pSrNUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0aceb2bd-6564-4501-9d4c-093d2067acf5"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "print(\"R2 score: \", r2_score(y_test, y_pred))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 score:  0.028551743423591014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghbvt3vVsMpS",
        "colab_type": "text"
      },
      "source": [
        "As you can see the R2 score is pretty bad (higher the better). \n",
        "\n",
        "Clearly we need to train our model for more number of epochs and also on the entire dataset. \n",
        "\n",
        "I leave that up to you to do."
      ]
    }
  ]
}